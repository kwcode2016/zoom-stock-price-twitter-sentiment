{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this is good', 'real bad', 'I like what happned', 'i hated that person', 'cats have 4 legs', 'I have shorted the stock, cuz i see a slowdown in business']\n"
     ]
    }
   ],
   "source": [
    "texts_raw = '''\n",
    "this is good\n",
    "real bad\n",
    "I like what happned\n",
    "i hated that person\n",
    "cats have 4 legs\n",
    "I have shorted the stock, cuz i see a slowdown in business\n",
    "'''\n",
    "\n",
    "texts = texts_raw.split('\\n')\n",
    "texts = [i for i in texts if i != '']\n",
    "print(texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading 300k tweets and getting sentiment on each one then saving that to CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load 300K Tweets zm-6-2019-04-01-2022-12-11-all-zm-tweets.jsonl\n",
    "file_path = 'zm-6-2019-04-01-2022-12-11-all-zm-tweets.jsonl' #full file. \n",
    "# file_path = 'zm-tweets-jan to april 2020.csv' # testing smaller file\n",
    "# file_path = 'zm_mismatch_df.csv'  # testing on mismatch only 5k\n",
    "# df = pd.read_csv(file_path)\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "# tweet_zm_df = pd.read_json(tweet_json, lines=True)\n",
    "# tweet_zm_df.head(10)\n",
    "# df = pd.read_json(file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 301098 entries, 0 to 301097\n",
      "Data columns (total 28 columns):\n",
      " #   Column            Non-Null Count   Dtype              \n",
      "---  ------            --------------   -----              \n",
      " 0   _type             301098 non-null  object             \n",
      " 1   url               301098 non-null  object             \n",
      " 2   date              301098 non-null  datetime64[ns, UTC]\n",
      " 3   content           301098 non-null  object             \n",
      " 4   renderedContent   301098 non-null  object             \n",
      " 5   id                301098 non-null  int64              \n",
      " 6   user              301098 non-null  object             \n",
      " 7   replyCount        301098 non-null  int64              \n",
      " 8   retweetCount      301098 non-null  int64              \n",
      " 9   likeCount         301098 non-null  int64              \n",
      " 10  quoteCount        301098 non-null  int64              \n",
      " 11  conversationId    301098 non-null  int64              \n",
      " 12  lang              301098 non-null  object             \n",
      " 13  source            301098 non-null  object             \n",
      " 14  sourceUrl         301098 non-null  object             \n",
      " 15  sourceLabel       301098 non-null  object             \n",
      " 16  outlinks          104914 non-null  object             \n",
      " 17  tcooutlinks       104914 non-null  object             \n",
      " 18  media             90458 non-null   object             \n",
      " 19  retweetedTweet    0 non-null       float64            \n",
      " 20  quotedTweet       22522 non-null   object             \n",
      " 21  inReplyToTweetId  48445 non-null   float64            \n",
      " 22  inReplyToUser     48445 non-null   object             \n",
      " 23  mentionedUsers    49517 non-null   object             \n",
      " 24  coordinates       2247 non-null    object             \n",
      " 25  place             2247 non-null    object             \n",
      " 26  hashtags          53340 non-null   object             \n",
      " 27  cashtags          300544 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(2), int64(6), object(19)\n",
      "memory usage: 64.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.shape\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp --- getting 5k tweets \n",
    "\n",
    "# # these 2 lines works well (need to convert to list)\n",
    "# texts = df['clean_tweet']\n",
    "# texts = list(texts)\n",
    "\n",
    "\n",
    "texts = df['content']\n",
    "texts = list(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301098"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# clean tweets and create a new col clean_tweets\n",
    "\n",
    "# filter tweets that have cashtags that are 3 or lower (will remove alot of the spam and news report tweets)\n",
    "\n",
    "# count remaining tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$ROKU $ARKK $TWLO $AMZN $DIS $NVAX $NVDA $AMD $MDB $DDOG $IWM $PYPL $SQ $SHOP $PTON $NOW $SNAP $ZM $NIO $CHWY $SPOT $NKE $TTD $UBER $ABNB $GME $TUP $BLNK $RIOT chopped around for months while going sideways before destruction\\n\\n$TSLA $AAPL making a super choppy bases now as well', '$ROKU $SQ $TSLA $ZM - 5 Investment Opportunities With Over 700% Upside, According to Cathie Wood https://t.co/9q4dcY4yLt', '$ROKU $SQ $TSLA $ZM - 5 Investment Opportunities With Over 700% Upside, According to Cathie Wood https://t.co/nG1UdnVT4N', '$ROKU $SQ $TSLA $ZM - 5 Investment Opportunities With Over 700% Upside, According to Cathie Wood https://t.co/ucHouBneQP', '$ROKU $SQ $TSLA $ZM - 5 Investment Opportunities With Over 700% Upside, According to Cathie Wood https://t.co/YG17kYRoWD', '$ROKU $SQ $TSLA $ZM - 5 Investment Opportunities With Over 700% Upside, According to Cathie Wood https://t.co/2OVmAcM6Pb', '$ROKU $SQ $TSLA $ZM - 5 Investment Opportunities With Over 700% Upside, According to Cathie Wood https://t.co/qdwRrvypRX', '$ROKU $SQ $TSLA $ZM - 5 Investment Opportunities With Over 700% Upside, According to Cathie Wood https://t.co/WV0XWidQBl', '$ROKU $SQ $TSLA $ZM - 5 Investment Opportunities With Over 700% Upside, According to Cathie Wood https://t.co/IOyjqYw7PS', \"Zoom Video $ZM is currently -4.3% at $72.16.\\nComponent no'1 of $ARKK https://t.co/iRrbhxR6vF\", '$ROKU $SQ $TSLA $ZM - 5 Investment Opportunities With Over 700% Upside, According to Cathie Wood https://t.co/70fuhIpq9Z', 'Great info! $SQ $ZM downloads catch my eye. https://t.co/04WSqxmc4L', '$ZM Trading Ideas | Awaiting Short signal. 62.5% Profitability based on 8 trades. Profit factor is 7.11. Learn more at https://t.co/uNaBDyBPlf. #ZMSTOCK #trading https://t.co/6wbvcckRYP', '$ZM  Top Analyst Price Targets for next week \\n https://t.co/bSkjack2oQ', '加えてロシアウクライナ戦争が起き、ロシアからの原油供給が絞られたことも株価上昇を後押ししている。\\n\\nもしワクチンが出来ていなかったら。\\nもしロシアウクライナ戦争がなかったら。\\n\\n石油株は今頃どうなっていただろうか。\\nワクチンが出来なかったら $ZM は、1,000ドルまで上げていたかもしれない。', '$zm \"$45,00 a day keeps the 9 to 5 away; For a limited time, we are opening our trading chat-room to the public&gt;~\\nhttps://t.co/nRPFqGpUzG', '#SaaS Retention Rates Updated. Last Reported Qtr:\\n$SNOW 165%\\n$PATH 126%\\n$DDOG&amp;gt;130%\\n$CFLT&amp;gt;130%\\n$SPLK 127%\\n$ESTC 125%\\n$ZM 117%\\n$S 134%\\n$CRWD&amp;gt;120%\\n$MDB&amp;gt;120%\\n$ZS&amp;gt;125%\\n$NET&amp;gt;\\nStock Alerts Discussion Group, Free to Join https://t.co/NR26rvZons https://t.co/j47ve8IfjD', '#SaaS Retention Rates Updated. Last Reported Qtr:\\n$SNOW 165%\\n$PATH 126%\\n$DDOG&amp;gt;130%\\n$CFLT&amp;gt;130%\\n$SPLK 127%\\n$ESTC 125%\\n$ZM 117%\\n$S 134%\\n$CRWD&amp;gt;120%\\n$MDB&amp;gt;120%\\n$ZS&amp;gt;125%\\\\nStocks Free Alerts Discussion Group, Click to Join   https://t.co/RQp2YMDY6g https://t.co/LNvQxo5nrE', '2d-2u rev - $ABT $CMCSA $DASH $DDOG $KR $LRCX $MU $PYPL $RH $SPOT $SBLK $SQ $TBT $TSM $UNG $WDC $ZIM $ZM\\n\\n2u-2d rev - $AXP $CLF $ETSY $FCX $FNKO $JNJ $K $LI $META $MRK $NIO $NUE $PTON $RTX $X $XME $XPEV', '\"Are you ready for your 10-Day free trial No credit Card required. Begin growing your portfolio with OptionAlarm Option Swing Trades today! https://t.co/fgKThJxj1A $AAPL $TSLA $ZM $SHOP $GILD \"', '#SaaS Retention Rates Updated. Last Reported Qtr:\\n$SNOW 165%\\n$PATH 126%\\n$DDOG&amp;gt;130%\\n$CFLT&amp;gt;130%\\n$SPLK 127%\\n$ESTC 125%\\n$ZM 117%\\n$S 134%\\n$CRWD&amp;gt;120%\\n$MDB&amp;gt;120%\\n$ZS&amp;gt;125%\\n$N\\nStock Intelligence Discussion Group, click jiaru  https://t.co/dylnZgQfZh https://t.co/Lx4EyDMibH', '#SaaS Retention Rates Updated. Last Reported Qtr:\\n$SNOW 165%\\n$PATH 126%\\n$DDOG&amp;gt;130%\\n$CFLT&amp;gt;130%\\n$SPLK 127%\\n$ESTC 125%\\n$ZM 117%\\n$S 134%\\n$CRWD&amp;gt;120%\\n$MDB&amp;gt;120%\\n$ZS&amp;gt;125%\\n$\\nStocks Free Alerts Discussion Group, Click to Join https://t.co/ZAKU7LNN3g https://t.co/WHS2BLFD5N', 'Alerted an entry for $AMD win of 32%. \\n us out\\n\\n$NAKD $TSLA $AAPL $NIO $SPY $INTC $GE $SNDL $NXTD $KGC $ZOM\\n$FCEL\\n$FEYE \\n$ZM\\n$AAL \\n$PLTR \\n$CCL \\n$MSFT \\n$PFE\\n$PLUG \\n$WFC \\n$AMD \\n$VXX\\nStocks, Options, Futures, Discussion Groups https://t.co/4HCtVQiiwQ https://t.co/0Y6JxZJyrs', \"The 2025 leaps popping up in @unusual_whales are interesting. $ZM 1/2025 130C. It's price at 1000 bucks but not at all implausible as a strike. Not one of my favorites but $ZM rallied to 125 in July, so it would not even take some dramatic bull market return. https://t.co/T7SiJL4zVj\", '$ZM  Top analyst price target for next week &gt;~  https://t.co/QgfF8ddUva', '$zm I made $1,400 trading in the first hour of market open today.\\nhttps://t.co/JrHINRDhYi', '$ZM   ALL THESE LEVELS POSTED AHEAD OF TIME BEFORE THE MARKET OPENED ➟➟  https://t.co/QgfF8ddUva', '$ZM احتمال 67 بكسر 72 \\n\\nولدينا الشارت الشهري ، تفنن فيه وعطني رايك https://t.co/PFTHHcm6O0', '$ZM Trading Ideas | Awaiting Short signal. 62.5% Profitability based on 8 trades. Profit factor is 7.11. Learn more at https://t.co/uNaBDyBPlf. #ZMSTOCK #trading https://t.co/xAiUx3YU32', '@unusual_whales ARK Innovation ETF $ARKK :\\n• Top holdings: $TSLA $ROKU $TDOC $SQ $ZM\\n• AUM: $7.67B https://t.co/JidYi0Vbni', '$zm  ALL THESE LEVELS POSTED AHEAD OF TIME BEFORE THE MARKET OPENED ➟. ..\\nhttps://t.co/eglFoIuR2C', '$ZM  Top analyst price target for next week &gt;~  https://t.co/FXedLd42Ff']\n"
     ]
    }
   ],
   "source": [
    "# WORKING WITH CUDA and adding 300k tweets to test\n",
    "\n",
    "# code wtih cuda reporting.\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA available:\" if cuda_available else \"CUDA not available\")\n",
    "\n",
    "# Load the RoBERTa tokenizer and model\n",
    "model_name = f'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name).to(\"cuda\" if cuda_available else \"cpu\")\n",
    "\n",
    "# Create a list of 17,000 sample texts (replace this with your actual data)\n",
    "# texts = [\"Sample text {}\".format(i) for i in range(17000)] #commented out to use my own text\n",
    "\n",
    "# Set the batch size (you may need to adjust this based on your GPU memory)\n",
    "batch_size = 32\n",
    "\n",
    "# Function to classify sentiment in a batch of texts\n",
    "def classify_sentiment(texts_batch):\n",
    "    print(texts_batch)\n",
    "    encoded_input = tokenizer(texts_batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    encoded_input = {key: value.to(\"cuda\" if cuda_available else \"cpu\") for key, value in encoded_input.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**encoded_input).logits\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "    print(probabilities)\n",
    "    # labels = [\"NEGATIVE\" if p < 0.5 else \"POSITIVE\" for p in probabilities[:, 1]]\n",
    "    max_indices = torch.argmax(probabilities, dim=1)\n",
    "    # Map indices to labels\n",
    "    labels_map = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "    labels = [labels_map[index.item()] for index in max_indices]\n",
    "    return labels\n",
    "    # return probabilities\n",
    "\n",
    "# Process the texts in batches\n",
    "sentiments = []\n",
    "num_batches = len(texts) // batch_size + int(len(texts) % batch_size > 0)\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    texts_batch = texts[i:i + batch_size]\n",
    "    sentiments_batch = classify_sentiment(texts_batch)\n",
    "    sentiments.extend(sentiments_batch)\n",
    "    \n",
    "    # Print progress\n",
    "    batches_completed = i // batch_size + 1\n",
    "    batches_left = num_batches - batches_completed\n",
    "    print(f\"Batch {batches_completed}/{num_batches} completed. Batches left: {batches_left}\")\n",
    "\n",
    "# Print the first 10 sentiment labels\n",
    "print(sentiments[:50])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentiments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39msentiment_r_latest\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m sentiments\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sentiments' is not defined"
     ]
    }
   ],
   "source": [
    "df['sentiment_r_latest'] = sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('mismatch_w_r_latest_sentiment.csv')\n",
    "df.to_csv('full300k_w_r_latest_sentiment_no_clean_no_finetuning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sentiment back into main df\n",
    "\n",
    "\n",
    "# save main 300ktweets_with_sentiment to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
